## time out
Multipart file로 약 300~500개의 파일을 업로드할 경우 업로드가 안된다고 한다.

그래서 로그를 살펴보았다.

502 Bad gateway 응답을 받았는데 
nginx의 로그를 살펴보니 다음과 같았다.

```
upstream prematurely closed connection while reading response header from upstream
```
그리고 Flask 앱에서는 다음과 같은 에러가 남겨져있었다.
```
WORKER TIMEOUT (pid:21)
```

결국 수많은 파일을 업로드하다가 시간초과가 나서 에러를 뿜는 것이다.

nginx 와 gunicorn 조합을 쓰고있는데 구글링을 해보니 이 둘의 설정을 바꾸라고 되어있다.

그래서 먼저 gunicorn 실행스크립트를 수정하여 타임아웃을 600초로 설정했다.

공식문서에서는 다음과 같이 옵션을 쓰라고 나와있다.
```
-t INT, --timeout INT
```

gunicorn의 timeout를 늘렸더니 다행히 502 에러는 안났지만 504 에러가 뜨기 시작했다. 

Time out의 경우 stackoverflow의 한 개발자의 답변에 의하면 보통 502는 nginx 뒷단에서 문제가 있을때 발생하고 504는 nginx 에서 문제가 있을때 발생한다고 한다.

nginx의 timeout 설정은 다음과 같이 바꾸면 된다고 한다.
```
proxy_connect_timeout 300;
proxy_send_timeout 300;
proxy_read_timeout 300;
send_timeout 300;
```

하지만 nginx 의 timeout은 제대로 적용하지 못했다.

사실 다량의 파일을 업로드하기위해서 timeout을 늘리는 것 자체가 좋지 않다고 한다. 

비동기가 아니기때문에 사용자가 하염없이 기다려야 한다는 것이다..

그래서 다량의 파일 업로드의 경우 redis같은 queue에 넣는 방식으로 구현하는게 좋을 것 같다.

신기하게도 위 방법을 적용하고나서 1000개까지 업로드되는것도 확인했지만.. 테스트를 계속 해보니 서버가 금방 죽어버린다.

현재 t2.medicum을 쓰고있는데 1000개를 한꺼번에 업로드하니 2~3GB의 메모리를 잡아먹는것같다.

자세히는 모르지만 거기서 부하가 걸린것으로 추측하고 있다..다음주에 좀 더 정확한 원인을 찾아봐야겠다.
